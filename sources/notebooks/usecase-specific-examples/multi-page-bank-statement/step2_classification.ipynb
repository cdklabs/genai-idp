{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Document Classification\n",
    "\n",
    "This notebook performs document classification using AWS Bedrock to identify document types and segments.\n",
    "\n",
    "**Inputs:**\n",
    "- Document object with OCR results from Step 1\n",
    "- Classification configuration\n",
    "- Document classes definition\n",
    "\n",
    "**Outputs:**\n",
    "- Document with classification results\n",
    "- Identified document sections and their types\n",
    "- Page-level classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Previous Step Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Import IDP libraries\n",
    "from idp_common.models import Document, Status\n",
    "from idp_common import classification\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger('idp_common.classification').setLevel(logging.INFO)\n",
    "logging.getLogger('idp_common.bedrock.client').setLevel(logging.INFO)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load document from previous step\n",
    "ocr_data_dir = Path(\".data/step1_ocr\")\n",
    "\n",
    "# Load document object from JSON\n",
    "document_path = ocr_data_dir / \"document.json\"\n",
    "with open(document_path, 'r') as f:\n",
    "    document = Document.from_json(f.read())\n",
    "\n",
    "# Load configuration directly from config files\n",
    "import yaml\n",
    "config_dir = Path(\"config\")\n",
    "CONFIG = {}\n",
    "\n",
    "# Load each configuration file\n",
    "config_files = [\n",
    "    \"classification.yaml\", \n",
    "    \"classes.yaml\"\n",
    "]\n",
    "\n",
    "for config_file in config_files:\n",
    "    config_path = config_dir / config_file\n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            file_config = yaml.safe_load(f)\n",
    "            CONFIG.update(file_config)\n",
    "        print(f\"Loaded {config_file}\")\n",
    "    else:\n",
    "        print(f\"Warning: {config_file} not found\")\n",
    "\n",
    "# Load environment info\n",
    "env_path = ocr_data_dir / \"environment.json\"\n",
    "with open(env_path, 'r') as f:\n",
    "    env_info = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['AWS_REGION'] = env_info['region']\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Modular-Pipeline'\n",
    "\n",
    "print(f\"Loaded document: {document.id}\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "print(f\"Number of pages: {document.num_pages}\")\n",
    "print(f\"Loaded configuration sections: {list(CONFIG.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Classification Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract classification configuration\n",
    "classification_config = CONFIG.get('classification', {})\n",
    "print(\"Classification Configuration:\")\n",
    "print(f\"Model: {classification_config.get('model')}\")\n",
    "print(f\"Classification Method: {classification_config.get('classificationMethod')}\")\n",
    "print(f\"Temperature: {classification_config.get('temperature')}\")\n",
    "print(f\"Max Tokens: {classification_config.get('max_tokens')}\")\n",
    "print(\"*\"*50)\n",
    "print(f\"System Prompt:\\n{classification_config.get('system_prompt')}\")\n",
    "print(\"*\"*50)\n",
    "print(f\"Task Prompt:\\n{classification_config.get('task_prompt')}\")\n",
    "print(\"*\"*50)\n",
    "\n",
    "# Display available document classes\n",
    "classes = CONFIG.get('classes', [])\n",
    "print(f\"\\nAvailable Document Classes: {len(classes)}\")\n",
    "for cls in classes:\n",
    "    print(f\"- {cls['name']}: {cls['description']}\")\n",
    "\n",
    "# Verify that Config specifies holistic classification\n",
    "print(\"\\n*****************************************************************\")\n",
    "print(f'CONFIG classificationMethod: {classification_config.get(\"classificationMethod\")}')\n",
    "print(\"*****************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification service with Bedrock backend\n",
    "classification_service = classification.ClassificationService(\n",
    "    config=CONFIG, \n",
    "    backend=\"bedrock\" \n",
    ")\n",
    "\n",
    "print(\"Classification service initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classify the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the document\n",
    "print(\"Classifying document...\")\n",
    "start_time = time.time()\n",
    "\n",
    "document = classification_service.classify_document(document)\n",
    "\n",
    "classification_time = time.time() - start_time\n",
    "print(f\"Classification completed in {classification_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classification results\n",
    "if document.sections:\n",
    "    print(\"\\nDetected sections:\")\n",
    "    for section in document.sections:\n",
    "        print(f\"Section {section.section_id}: {section.classification}\")\n",
    "        print(f\"  Pages: {section.page_ids}\")\n",
    "        if hasattr(section, 'reason') and section.reason:\n",
    "            print(f\"  Reason: {section.reason}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"\\nNo sections detected\")\n",
    "\n",
    "# Show page classification\n",
    "print(\"\\nPage-level classifications:\")\n",
    "for page_id, page in sorted(document.pages.items()):\n",
    "    print(f\"Page {page_id}: {page.classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Results for Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory for this step\n",
    "data_dir = Path(\".data/step2_classification\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save updated document object as JSON\n",
    "document_path = data_dir / \"document.json\"\n",
    "with open(document_path, 'w') as f:\n",
    "    f.write(document.to_json())\n",
    "\n",
    "# Save configuration (pass through)\n",
    "config_path = data_dir / \"config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "# Save environment info (pass through)\n",
    "env_path = data_dir / \"environment.json\"\n",
    "with open(env_path, 'w') as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "\n",
    "# Save classification-specific results summary\n",
    "classification_results = {\n",
    "    'processing_time_seconds': classification_time,\n",
    "    'classification_method': classification_config.get('classificationMethod'),\n",
    "    'model_used': classification_config.get('model'),\n",
    "    'num_sections': len(document.sections) if document.sections else 0,\n",
    "    'sections': [\n",
    "        {\n",
    "            'section_id': section.section_id,\n",
    "            'classification': section.classification,\n",
    "            'page_ids': section.page_ids,\n",
    "            'reason': getattr(section, 'reason', None)\n",
    "        } for section in (document.sections or [])\n",
    "    ],\n",
    "    'page_classifications': {\n",
    "        page_id: page.classification for page_id, page in document.pages.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "classification_results_path = data_dir / \"classification_results.json\"\n",
    "with open(classification_results_path, 'w') as f:\n",
    "    json.dump(classification_results, f, indent=2)\n",
    "\n",
    "print(f\"Saved document to: {document_path}\")\n",
    "print(f\"Saved configuration to: {config_path}\")\n",
    "print(f\"Saved environment info to: {env_path}\")\n",
    "print(f\"Saved classification results to: {classification_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 2: Classification Complete ===\")\n",
    "print(f\"âœ… Document classified: {document.id}\")\n",
    "print(f\"âœ… Sections identified: {len(document.sections) if document.sections else 0}\")\n",
    "print(f\"âœ… Processing time: {classification_time:.2f} seconds\")\n",
    "print(f\"âœ… Method used: {classification_config.get('classificationMethod')}\")\n",
    "print(f\"âœ… Model used: {classification_config.get('model')}\")\n",
    "print(f\"âœ… Data saved to: .data/step2_classification/\")\n",
    "print(\"\\nðŸ“Œ Next step: Run step3_extraction.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
