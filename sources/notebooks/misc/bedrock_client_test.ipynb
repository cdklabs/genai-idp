{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock Client Testing Notebook\n",
    "\n",
    "This notebook tests the `invoke_model` method in the Bedrock client (`genaiic-idp-accelerator/lib/idp_common_pkg/idp_common/bedrock/client.py`). It includes tests for:\n",
    "\n",
    "1. Claude models with different parameter combinations\n",
    "2. Nova models with different parameter combinations\n",
    "3. Parameter validation and error handling\n",
    "\n",
    "Each test verifies that parameters are correctly passed to the Bedrock API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, we'll import the necessary libraries and set up logging to see debug output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: idp_common 0.2.19\n",
      "Uninstalling idp_common-0.2.19:\n",
      "  Successfully uninstalled idp_common-0.2.19\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Version: 0.2.19\n",
      "Location: /Users/miislamg/miniconda3/envs/genaiic-idp-accelerator/lib/python3.12/site-packages\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Let's make sure that modules are autoreloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOTDIR=\"../..\"\n",
    "# First uninstall existing package (to ensure we get the latest version)\n",
    "%pip uninstall -y idp_common\n",
    "\n",
    "# Install the IDP common package with all components in development mode\n",
    "%pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[dev, all]\"\n",
    "\n",
    "# Note: We can also install specific components like:\n",
    "# %pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[ocr,classification,extraction,evaluation]\"\n",
    "\n",
    "# Check installed version\n",
    "%pip show idp_common | grep -E \"Version|Location\"\n",
    "\n",
    "# Optionally use a .env file for environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  \n",
    "except ImportError:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "from typing import Dict, Any, List, Optional, Union\n",
    "\n",
    "# Import the Bedrock client\n",
    "from idp_common.bedrock.client import BedrockClient, invoke_model\n",
    "\n",
    "# Set up logging to see debug output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Create a logger for this notebook\n",
    "logger = logging.getLogger('bedrock_client_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Let's create some helper functions to make testing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response_summary(response: Dict[str, Any]) -> None:\n",
    "    \"\"\"Print a summary of the Bedrock response.\"\"\"\n",
    "    if not response:\n",
    "        print(\"Empty response\")\n",
    "        return\n",
    "        \n",
    "    # Extract the actual response from the wrapper\n",
    "    bedrock_response = response.get(\"response\", {})\n",
    "    \n",
    "    # Print the output text\n",
    "    if \"output\" in bedrock_response and \"message\" in bedrock_response[\"output\"]:\n",
    "        message = bedrock_response[\"output\"][\"message\"]\n",
    "        if \"content\" in message and isinstance(message[\"content\"], list) and len(message[\"content\"]) > 0:\n",
    "            text = message[\"content\"][0].get(\"text\", \"\")\n",
    "            print(f\"Response text (truncated): {text[:200]}...\")\n",
    "    \n",
    "    # Print usage information\n",
    "    if \"usage\" in bedrock_response:\n",
    "        usage = bedrock_response[\"usage\"]\n",
    "        print(f\"Usage: {usage}\")\n",
    "    \n",
    "    # Print metering information\n",
    "    if \"metering\" in response:\n",
    "        print(f\"Metering: {response['metering']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Cases for Claude Models\n",
    "\n",
    "Now we'll test the `invoke_model` method with a Claude model using different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Bedrock client instance\n",
    "claude_client = BedrockClient(region=\"us-west-2\")\n",
    "\n",
    "# Define the Claude model ID\n",
    "claude_model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "\n",
    "# Define a simple system prompt\n",
    "system_prompt = \"You are a helpful assistant that provides concise answers.\"\n",
    "\n",
    "# Define a simple user message\n",
    "content = [{\"text\": \"What is Amazon Bedrock?\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claude Test with Multiple Parameters\n",
    "\n",
    "Let's test with multiple parameters: temperature, top_p, top_k, and max_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Claude model with multiple parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 02:33:57,047 - idp_common.bedrock.client - INFO - Bedrock request attempt 1/8:\n",
      "2025-05-09 02:33:58,805 - idp_common.bedrock.client - INFO - Response: {'ResponseMetadata': {'RequestId': '19b87967-8866-4e4f-a15d-42697edab9e3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Fri, 09 May 2025 09:33:58 GMT', 'content-type': 'application/json', 'content-length': '569', 'connection': 'keep-alive', 'x-amzn-requestid': '19b87967-8866-4e4f-a15d-42697edab9e3'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'Amazon Bedrock is a fully managed service by AWS that provides access to high-performing foundation models from various AI companies through a single API. It allows developers to build and scale generative AI applications without having to manage the underlying infrastructure.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 25, 'outputTokens': 51, 'totalTokens': 76, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 1543}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response summary:\n",
      "Response text (truncated): Amazon Bedrock is a fully managed service by AWS that provides access to high-performing foundation models from various AI companies through a single API. It allows developers to build and scale gener...\n",
      "Usage: {'inputTokens': 25, 'outputTokens': 51, 'totalTokens': 76, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}\n",
      "Metering: {'bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0': {'inputTokens': 25, 'outputTokens': 51, 'totalTokens': 76, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Testing Claude model with multiple parameters...\")\n",
    "    response = claude_client.invoke_model(\n",
    "        model_id=claude_model_id,\n",
    "        system_prompt=system_prompt,\n",
    "        content=content,\n",
    "        temperature=0.8,\n",
    "        top_p=0.9,\n",
    "        top_k=40,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResponse summary:\")\n",
    "    print_response_summary(response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Cases for Nova Models\n",
    "\n",
    "Now we'll test the `invoke_model` method with a Nova model using different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Bedrock client instance\n",
    "nova_client = BedrockClient(region=\"us-west-2\")\n",
    "\n",
    "# Define the Nova model ID\n",
    "nova_model_id = \"us.amazon.nova-pro-v1:0\"\n",
    "\n",
    "# Define a simple system prompt\n",
    "nova_system_prompt = \"You are a helpful assistant that provides concise answers.\"\n",
    "\n",
    "# Define a simple user message\n",
    "nova_content = [{\"text\": \"What is Amazon Bedrock?\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nova Test with Multiple Parameters\n",
    "\n",
    "Now let's test with multiple parameters: temperature, top_p, top_k, and max_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 02:33:59,552 - idp_common.bedrock.client - INFO - Bedrock request attempt 1/8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Nova model with multiple parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 02:34:00,398 - idp_common.bedrock.client - INFO - Response: {'ResponseMetadata': {'RequestId': '61ebd327-d396-4aaf-b9ce-a73e61f46eb3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Fri, 09 May 2025 09:34:00 GMT', 'content-type': 'application/json', 'content-length': '323', 'connection': 'keep-alive', 'x-amzn-requestid': '61ebd327-d396-4aaf-b9ce-a73e61f46eb3'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'Amazon Bedrock is a service that simplifies building and scaling generative AI applications using foundation models from leading AI companies.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 16, 'outputTokens': 22, 'totalTokens': 38}, 'metrics': {'latencyMs': 759}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response summary:\n",
      "Response text (truncated): Amazon Bedrock is a service that simplifies building and scaling generative AI applications using foundation models from leading AI companies....\n",
      "Usage: {'inputTokens': 16, 'outputTokens': 22, 'totalTokens': 38}\n",
      "Metering: {'bedrock/us.amazon.nova-pro-v1:0': {'inputTokens': 16, 'outputTokens': 22, 'totalTokens': 38}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Testing Nova model with multiple parameters...\")\n",
    "    response = nova_client.invoke_model(\n",
    "        model_id=nova_model_id,\n",
    "        system_prompt=nova_system_prompt,\n",
    "        content=nova_content,\n",
    "        temperature=0.8,\n",
    "        top_p=0.9,\n",
    "        top_k=40,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResponse summary:\")\n",
    "    print_response_summary(response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiic-idp-accelerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
