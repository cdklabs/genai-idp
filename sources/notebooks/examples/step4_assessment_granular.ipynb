{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4: Assessment (Granular) with Bounding Boxes\n",
        "\n",
        "This notebook demonstrates the **granular assessment** approach with **automatic bounding box processing** for evaluating extraction confidence using AWS Bedrock.\n",
        "\n",
        "**Key Features:**\n",
        "- Multiple focused inferences instead of single large inference\n",
        "- **Automatic spatial localization with bounding boxes**\n",
        "- **Visual annotation of extracted fields**\n",
        "- Prompt caching for cost optimization\n",
        "- Parallel processing for reduced latency\n",
        "- Better handling of complex documents with many attributes\n",
        "\n",
        "**Inputs:**\n",
        "- Document object with extraction results from Step 3\n",
        "- Granular assessment configuration with enhanced prompts\n",
        "- Document classes with confidence thresholds\n",
        "\n",
        "**Outputs:**\n",
        "- Document with enhanced assessment results including geometry data\n",
        "- Detailed confidence scores and reasoning for each attribute\n",
        "- **Bounding box coordinates for spatial localization**\n",
        "- **Visual annotation of document pages with extracted fields**\n",
        "- Performance metrics showing granular processing benefits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Package Installation\n",
        "\n",
        "First, let's ensure we have the latest version of the IDP common package with bounding box support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOTDIR=\"../..\"\n",
        "\n",
        "# Let's make sure that modules are autoreloaded\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# First uninstall existing package (to ensure we get the latest version)\n",
        "%pip uninstall -y idp_common\n",
        "\n",
        "# Install the IDP common package with all components in development mode\n",
        "%pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[dev, all]\"\n",
        "\n",
        "# Check installed version\n",
        "%pip show idp_common | grep -E \"Version|Location\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Previous Step Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import boto3\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Import IDP libraries\n",
        "from idp_common.models import Document, Status\n",
        "from idp_common import assessment\n",
        "\n",
        "# Import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "logging.getLogger('idp_common.assessment.granular_service').setLevel(logging.INFO)\n",
        "logging.getLogger('idp_common.bedrock.client').setLevel(logging.INFO)\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"Granular assessment with automatic bounding box support enabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load document from previous step\n",
        "extraction_data_dir = Path(\".data/step3_extraction\")\n",
        "\n",
        "# Load document object from JSON\n",
        "document_path = extraction_data_dir / \"document.json\"\n",
        "with open(document_path, 'r') as f:\n",
        "    document = Document.from_json(f.read())\n",
        "\n",
        "# Load configuration - use enhanced config with bounding boxes\n",
        "config_dir = Path(\"config\")\n",
        "CONFIG = {}\n",
        "\n",
        "config_files = [\n",
        "    \"assessment_with_bounding_boxes.yaml\",  # Enhanced config with spatial prompts\n",
        "    \"classes.yaml\"\n",
        "]\n",
        "\n",
        "# Override to enable granular assessment\n",
        "for config_file in config_files:\n",
        "    config_path = config_dir / config_file\n",
        "    if config_path.exists():\n",
        "        with open(config_path, 'r') as f:\n",
        "            file_config = yaml.safe_load(f)\n",
        "            CONFIG.update(file_config)\n",
        "        print(f\"Loaded {config_file}\")\n",
        "    else:\n",
        "        print(f\"Warning: {config_file} not found\")\n",
        "\n",
        "# Enable granular assessment\n",
        "if 'assessment' not in CONFIG:\n",
        "    CONFIG['assessment'] = {}\n",
        "if 'granular' not in CONFIG['assessment']:\n",
        "    CONFIG['assessment']['granular'] = {}\n",
        "CONFIG['assessment']['granular']['enabled'] = True\n",
        "\n",
        "# Load environment info\n",
        "env_path = extraction_data_dir / \"environment.json\"\n",
        "with open(env_path, 'r') as f:\n",
        "    env_info = json.load(f)\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['AWS_REGION'] = env_info['region']\n",
        "os.environ['METRIC_NAMESPACE'] = 'IDP-Modular-Pipeline'\n",
        "\n",
        "print(f\"Loaded document: {document.id}\")\n",
        "print(f\"Document status: {document.status.value}\")\n",
        "print(f\"Number of sections: {len(document.sections) if document.sections else 0}\")\n",
        "print(f\"Configuration sections: {list(CONFIG.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Granular Assessment Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract assessment configuration\n",
        "assessment_config = CONFIG.get('assessment', {})\n",
        "granular_config = assessment_config.get('granular', {})\n",
        "\n",
        "print(\"=== Assessment Configuration ===\")\n",
        "print(f\"Model: {assessment_config.get('model')}\")\n",
        "print(f\"Temperature: {assessment_config.get('temperature')}\")\n",
        "print(f\"Default Confidence Threshold: {assessment_config.get('default_confidence_threshold')}\")\n",
        "\n",
        "print(\"\\n=== Granular Configuration ===\")\n",
        "print(f\"Enabled: {granular_config.get('enabled', False)}\")\n",
        "print(f\"Max Workers: {granular_config.get('max_workers', 4)}\")\n",
        "print(f\"Simple Batch Size: {granular_config.get('simple_batch_size', 3)}\")\n",
        "print(f\"List Batch Size: {granular_config.get('list_batch_size', 1)}\")\n",
        "\n",
        "print(\"\\n=== Enhanced Bounding Box Prompts ===\")\n",
        "task_prompt = assessment_config.get('task_prompt', '')\n",
        "has_spatial_guidelines = 'spatial-localization-guidelines' in task_prompt\n",
        "has_bbox_instructions = 'bbox:' in task_prompt\n",
        "print(f\"Has spatial localization guidelines: {has_spatial_guidelines}\")\n",
        "print(f\"Has bounding box instructions: {has_bbox_instructions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create assessment service - will automatically use granular if enabled\n",
        "assessment_service = assessment.AssessmentService(config=CONFIG)\n",
        "\n",
        "print(f\"Assessment service initialized: {type(assessment_service._service).__name__}\")\n",
        "service_type = 'Granular' if 'Granular' in type(assessment_service._service).__name__ else 'Original'\n",
        "print(f\"Service type: {service_type}\")\n",
        "print(\"✅ Automatic bounding box processing enabled for granular assessment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_s3_uri(uri):\n",
        "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
        "    bucket = parts[0]\n",
        "    key = \"/\".join(parts[1:])\n",
        "    return bucket, key\n",
        "\n",
        "def load_json_from_s3(uri):\n",
        "    s3_client = boto3.client('s3')\n",
        "    bucket, key = parse_s3_uri(uri)\n",
        "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
        "    content = response['Body'].read().decode('utf-8')\n",
        "    return json.loads(content)\n",
        "\n",
        "def load_image_from_s3(uri):\n",
        "    s3_client = boto3.client('s3')\n",
        "    bucket, key = parse_s3_uri(uri)\n",
        "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
        "    image_data = response['Body'].read()\n",
        "    return Image.open(io.BytesIO(image_data))\n",
        "\n",
        "print(\"Helper functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Assess Extraction Results with Granular Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Assessing extraction confidence using granular approach with bounding boxes...\")\n",
        "\n",
        "if not document.sections:\n",
        "    print(\"No sections found in document. Cannot proceed with assessment.\")\n",
        "else:\n",
        "    assessment_results = []\n",
        "    \n",
        "    # Process each section that has extraction results (limit to first 2)\n",
        "    sections_with_extractions = [s for s in document.sections if hasattr(s, 'extraction_result_uri') and s.extraction_result_uri]\n",
        "    n = min(2, len(sections_with_extractions))\n",
        "    \n",
        "    print(f\"Found {len(sections_with_extractions)} sections with extraction results\")\n",
        "    print(f\"Processing first {n} sections for granular assessment...\")\n",
        "    \n",
        "    for i, section in enumerate(sections_with_extractions[:n]):\n",
        "        print(f\"\\n--- Granular Assessment: Section {i+1}/{n} ---\")\n",
        "        print(f\"Section ID: {section.section_id}\")\n",
        "        print(f\"Classification: {section.classification}\")\n",
        "        \n",
        "        # Process section assessment\n",
        "        start_time = time.time()\n",
        "        document = assessment_service.process_document_section(\n",
        "            document=document,\n",
        "            section_id=section.section_id\n",
        "        )\n",
        "        assessment_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"✅ Granular assessment completed in {assessment_time:.2f} seconds\")\n",
        "        \n",
        "        # Show granular performance metrics\n",
        "        try:\n",
        "            updated_extraction_data = load_json_from_s3(section.extraction_result_uri)\n",
        "            metadata = updated_extraction_data.get('metadata', {})\n",
        "            \n",
        "            if metadata.get('granular_assessment_used'):\n",
        "                print(f\"📊 Granular Tasks: {metadata.get('assessment_tasks_total', 'N/A')} total\")\n",
        "                print(f\"   ✅ Successful: {metadata.get('assessment_tasks_successful', 'N/A')}\")\n",
        "                print(f\"   ❌ Failed: {metadata.get('assessment_tasks_failed', 'N/A')}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load granular metadata: {e}\")\n",
        "        \n",
        "        assessment_results.append({\n",
        "            'section_id': section.section_id,\n",
        "            'classification': section.classification,\n",
        "            'processing_time': assessment_time,\n",
        "            'extraction_result_uri': section.extraction_result_uri\n",
        "        })\n",
        "    \n",
        "    print(f\"\\n🎉 Granular assessment with bounding boxes complete for {n} sections!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Display Assessment Results with Spatial Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_granular_assessment_with_geometry(data, attr_name=\"\", indent=\"  \"):\n",
        "    if isinstance(data, dict):\n",
        "        if 'confidence' in data:\n",
        "            confidence = data.get('confidence', 0)\n",
        "            threshold = data.get('confidence_threshold', 0.9)\n",
        "            reason = data.get('confidence_reason', 'No reason')\n",
        "            geometry = data.get('geometry', [])\n",
        "            \n",
        "            status = \"✅\" if confidence >= threshold else \"⚠️\"\n",
        "            print(f\"{indent}{status} {attr_name}: {confidence:.3f} (threshold: {threshold})\")\n",
        "            print(f\"{indent}   {reason[:100]}{'...' if len(reason) > 100 else ''}\")\n",
        "            \n",
        "            if geometry:\n",
        "                bbox = geometry[0]['boundingBox']\n",
        "                page = geometry[0]['page']\n",
        "                print(f\"{indent}   📍 Page {page}: {bbox['top']*100:.1f}%,{bbox['left']*100:.1f}% ({bbox['width']*100:.1f}%×{bbox['height']*100:.1f}%)\")\n",
        "        else:\n",
        "            print(f\"{indent}{attr_name} (Group):\")\n",
        "            for k, v in data.items():\n",
        "                display_granular_assessment_with_geometry(v, k, indent + \"  \")\n",
        "    elif isinstance(data, list):\n",
        "        print(f\"{indent}{attr_name} (List - {len(data)} items):\")\n",
        "        for i, item in enumerate(data[:3]):  # Show first 3\n",
        "            print(f\"{indent}  📄 Item {i+1}:\")\n",
        "            for k, v in item.items():\n",
        "                display_granular_assessment_with_geometry(v, k, indent + \"    \")\n",
        "        if len(data) > 3:\n",
        "            print(f\"{indent}  ... {len(data)-3} more items\")\n",
        "\n",
        "print(\"Enhanced granular assessment display function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Granular Assessment Results with Bounding Boxes ===\")\n",
        "\n",
        "geometry_data_by_page = {}\n",
        "\n",
        "if document.sections:\n",
        "    sections_with_extractions = [s for s in document.sections if hasattr(s, 'extraction_result_uri') and s.extraction_result_uri]\n",
        "    \n",
        "    for section in sections_with_extractions[:2]:\n",
        "        print(f\"\\n--- {section.section_id} ({section.classification}) ---\")\n",
        "        \n",
        "        try:\n",
        "            extraction_data = load_json_from_s3(section.extraction_result_uri)\n",
        "            \n",
        "            # Show granular metrics\n",
        "            metadata = extraction_data.get('metadata', {})\n",
        "            if metadata.get('granular_assessment_used'):\n",
        "                print(f\"📊 Granular: {metadata.get('assessment_tasks_total', 0)} tasks in {metadata.get('assessment_time_seconds', 0):.1f}s\")\n",
        "            \n",
        "            explainability_info = extraction_data.get('explainability_info', [])\n",
        "            if explainability_info:\n",
        "                assessments = explainability_info[0]\n",
        "                \n",
        "                # Display and collect geometry data\n",
        "                geometry_count = 0\n",
        "                for attr_name, attr_data in assessments.items():\n",
        "                    display_granular_assessment_with_geometry(attr_data, attr_name)\n",
        "                    \n",
        "                    # Collect geometry data for visualization\n",
        "                    if isinstance(attr_data, dict) and 'geometry' in attr_data:\n",
        "                        geometry_count += 1\n",
        "                        for geom in attr_data['geometry']:\n",
        "                            page = geom.get('page', 1)\n",
        "                            if page not in geometry_data_by_page:\n",
        "                                geometry_data_by_page[page] = []\n",
        "                            geometry_data_by_page[page].append({\n",
        "                                'attr_name': attr_name,\n",
        "                                'confidence': attr_data.get('confidence', 0),\n",
        "                                'geometry': geom,\n",
        "                                'section': section.classification\n",
        "                            })\n",
        "                \n",
        "                print(f\"📍 Attributes with spatial data: {geometry_count}/{len(assessments)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "print(f\"\\n📍 Total pages with geometry data: {len(geometry_data_by_page)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Bounding Boxes from Granular Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if geometry_data_by_page and document.pages:\n",
        "    print(\"\\n🎨 Creating granular assessment bounding box visualizations...\")\n",
        "    \n",
        "    for page_num, bbox_list in geometry_data_by_page.items():\n",
        "        print(f\"\\n--- Visualizing Page {page_num} ({len(bbox_list)} fields) ---\")\n",
        "        \n",
        "        page_id = str(page_num)\n",
        "        if page_id in document.pages:\n",
        "            page = document.pages[page_id]\n",
        "            \n",
        "            try:\n",
        "                image = load_image_from_s3(page.image_uri)\n",
        "                \n",
        "                # Create visualization\n",
        "                fig, ax = plt.subplots(1, 1, figsize=(12, 16))\n",
        "                ax.imshow(image)\n",
        "                ax.set_title(f\"Granular Assessment - Page {page_num}\", fontsize=14, fontweight='bold')\n",
        "                ax.axis('off')\n",
        "                \n",
        "                img_width, img_height = image.size\n",
        "                colors_used = set()\n",
        "                \n",
        "                for item in bbox_list:\n",
        "                    bbox = item['geometry']['boundingBox']\n",
        "                    confidence = item['confidence']\n",
        "                    \n",
        "                    # Convert normalized to pixel coordinates\n",
        "                    left = bbox['left'] * img_width\n",
        "                    top = bbox['top'] * img_height\n",
        "                    width = bbox['width'] * img_width\n",
        "                    height = bbox['height'] * img_height\n",
        "                    \n",
        "                    # Color based on confidence\n",
        "                    if confidence >= 0.9:\n",
        "                        color = 'green'\n",
        "                    elif confidence >= 0.7:\n",
        "                        color = 'orange'\n",
        "                    else:\n",
        "                        color = 'red'\n",
        "                    colors_used.add(color)\n",
        "                    \n",
        "                    # Draw rectangle\n",
        "                    rect = patches.Rectangle(\n",
        "                        (left, top), width, height,\n",
        "                        linewidth=2, edgecolor=color, facecolor='none', alpha=0.8\n",
        "                    )\n",
        "                    ax.add_patch(rect)\n",
        "                    \n",
        "                    # Add label\n",
        "                    label = f\"{item['attr_name']} ({confidence:.2f})\"\n",
        "                    ax.text(\n",
        "                        left, max(0, top - 10), label,\n",
        "                        fontsize=8, color=color, fontweight='bold',\n",
        "                        bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='white', alpha=0.8)\n",
        "                    )\n",
        "                \n",
        "                # Add legend\n",
        "                if colors_used:\n",
        "                    legend_elements = []\n",
        "                    if 'green' in colors_used:\n",
        "                        legend_elements.append(patches.Patch(color='green', label='High Confidence (≥0.9)'))\n",
        "                    if 'orange' in colors_used:\n",
        "                        legend_elements.append(patches.Patch(color='orange', label='Medium Confidence (≥0.7)'))\n",
        "                    if 'red' in colors_used:\n",
        "                        legend_elements.append(patches.Patch(color='red', label='Low Confidence (<0.7)'))\n",
        "                    ax.legend(handles=legend_elements, loc='upper right')\n",
        "                \n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                \n",
        "                print(f\"✅ Granular assessment visualization: {len(bbox_list)} fields on page {page_num}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error visualizing page {page_num}: {e}\")\nelse:\n    print(\"\\n📍 No geometry data available for visualization\")\n    print(\"   This could mean the LLM didn't provide bounding box coordinates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Granular Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Granular Performance Analysis with Bounding Boxes ===\")\n",
        "\n",
        "if document.sections:\n",
        "    sections_with_extractions = [s for s in document.sections if hasattr(s, 'extraction_result_uri') and s.extraction_result_uri]\n",
        "    \n",
        "    total_tasks = 0\n",
        "    total_time = 0\n",
        "    total_geometry_fields = sum(len(bbox_list) for bbox_list in geometry_data_by_page.values())\n",
        "    \n",
        "    for section in sections_with_extractions[:2]:\n",
        "        try:\n",
        "            extraction_data = load_json_from_s3(section.extraction_result_uri)\n",
        "            metadata = extraction_data.get('metadata', {})\n",
        "            \n",
        "            if metadata.get('granular_assessment_used'):\n",
        "                tasks = metadata.get('assessment_tasks_total', 0)\n",
        "                time_taken = metadata.get('assessment_time_seconds', 0)\n",
        "                \n",
        "                total_tasks += tasks\n",
        "                total_time += time_taken\n",
        "                \n",
        "                print(f\"\\nSection {section.section_id}:\")\n",
        "                print(f\"  • Granular tasks: {tasks}\")\n",
        "                print(f\"  • Processing time: {time_taken:.2f}s\")\n",
        "                print(f\"  • Avg time per task: {time_taken/tasks:.3f}s\" if tasks > 0 else \"  • No tasks\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing section {section.section_id}: {e}\")\n",
        "    \n",
        "    if total_tasks > 0:\n",
        "        print(f\"\\n📈 Overall Granular Performance:\")\n",
        "        print(f\"  • Total assessment tasks: {total_tasks}\")\n",
        "        print(f\"  • Total processing time: {total_time:.2f}s\")\n",
        "        print(f\"  • Average time per task: {total_time/total_tasks:.3f}s\")\n",
        "        print(f\"  • Fields with spatial data: {total_geometry_fields}\")\n",
        "        print(f\"  • Pages with visualizations: {len(geometry_data_by_page)}\")\n",
        "        \n",
        "        print(f\"\\n💡 Granular + Bounding Box Benefits:\")\n",
        "        print(f\"  • Focused assessments: Each task handles 1-3 attributes\")\n",
        "        print(f\"  • Parallel processing: Multiple tasks run concurrently\")\n",
        "        print(f\"  • Automatic spatial data: Bbox → geometry conversion in each task\")\n",
        "        print(f\"  • Prompt caching: Reduces token costs by 80-90%\")\n",
        "        print(f\"  • Visual validation: See exactly where each field is located\")\n",
        "else:\n",
        "    print(\"No sections available for performance analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results for Next Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data directory for this step\n",
        "data_dir = Path(\".data/step4_assessment_granular\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save updated document object as JSON\n",
        "document_path = data_dir / \"document.json\"\n",
        "with open(document_path, 'w') as f:\n",
        "    f.write(document.to_json())\n",
        "\n",
        "# Save configuration (pass through)\n",
        "config_path = data_dir / \"config.json\"\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "# Save environment info (pass through)\n",
        "env_path = data_dir / \"environment.json\"\n",
        "with open(env_path, 'w') as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved document to: {document_path}\")\n",
        "print(f\"Saved configuration to: {config_path}\")\n",
        "print(f\"Saved environment info to: {env_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sections_assessed = len(assessment_results) if 'assessment_results' in locals() else 0\n",
        "total_geometry = sum(len(bbox_list) for bbox_list in geometry_data_by_page.values())\n",
        "\n",
        "print(\"=== Step 4: Granular Assessment with Bounding Boxes Complete ===\")\n",
        "print(f\"✅ Document processed: {document.id}\")\n",
        "print(f\"✅ Sections assessed: {sections_assessed}\")\n",
        "print(f\"✅ Granular approach used: {granular_config.get('enabled', False)}\")\n",
        "print(f\"✅ Fields with spatial data: {total_geometry}\")\n",
        "print(f\"✅ Model used: {assessment_config.get('model')}\")\n",
        "\n",
        "print(\"\\n📌 Next step: Run step5_summarization.ipynb\")\n",
        "print(\"\\n📋 Granular Assessment + Bounding Box Features Demonstrated:\")\n",
        "print(\"  • Multiple focused inferences with spatial localization\")\n",
        "print(\"  • Automatic bounding box conversion (bbox → geometry)\")\n",
        "print(\"  • Parallel processing with visual annotation\")\n",
        "print(\"  • Prompt caching for cost optimization (80-90% savings)\")\n",
        "print(\"  • Enhanced performance metrics and task breakdown\")\n",
        "print(\"  • Better handling of complex documents with spatial validation\")\n",
        "print(\"  • UI-compatible geometry format output\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
